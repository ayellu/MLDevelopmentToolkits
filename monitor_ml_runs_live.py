# -*- coding: utf-8 -*-
"""Monitor-ML-runs-live.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-7oMc36FCOfKwnugvDIYXTCaux8TBC4J
"""

#installing dependecies
#!pip install neptune-client tensorflow

import numpy as np
import tensorflow.keras as keras
from tensorflow.keras.utils  import to_categorical
from keras import models
from keras import layers

PARAMS = {'epoch_nr': 10,
          'batch_size': 256,
          'lr': 0.005,
          'momentum': 0.4,
          'use_nesterov': True,
          'unit_nr': 256,
          'dropout': 0.05}
imdb = keras.datasets.imdb
(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=10000)
data = np.concatenate((training_data, testing_data), axis=0)
targets = np.concatenate((training_targets, testing_targets), axis=0)
print("Categories:", np.unique(targets))
print("Number of unique words:", len(np.unique(np.hstack(data))))

length = [len(i) for i in data]
print("Average Review length:", np.mean(length))
print("Standard Deviation:", round(np.std(length)))

print("Label:", targets[0])
print(data[0])

index = imdb.get_word_index()
reverse_index = dict([(value, key) for (key, value) in index.items()]) 
decoded = " ".join( [reverse_index.get(i - 3, "#") for i in data[0]] )
print(decoded)

def vectorize(sequences, dimension = 10000):
  results = np.zeros((len(sequences), dimension))
  for i, sequence in enumerate(sequences):
    results[i, sequence] = 1
  return results
 
data = vectorize(data)
targets = np.array(targets).astype("float32")

test_x = data[:10000]
test_y = targets[:10000]
train_x = data[10000:]
train_y = targets[10000:]

optimizer = keras.optimizers.SGD(lr=PARAMS['lr'],
                                 momentum=PARAMS['momentum'],
                                 nesterov=PARAMS['use_nesterov'], )


model = models.Sequential()
model.add(layers.Dense(50, activation = "relu", input_shape=(10000, )))
# Hidden - Layers
model.add(layers.Dropout(0.3, noise_shape=None, seed=None))
model.add(layers.Dense(50, activation = "relu"))
model.add(layers.Dropout(0.2, noise_shape=None, seed=None))
model.add(layers.Dense(50, activation = "relu"))
# Output- Layer
model.add(layers.Dense(1, activation = "sigmoid"))
model.summary()


model.compile(optimizer=optimizer,
              loss='binary_crossentropy',
              metrics=['accuracy'])

"""## Step 2: Initialize Neptune

Connects your script to Neptune application. 
"""

import neptune

neptune.init(
    project_qualified_name="svda/FinalProject",
    api_token="eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJkZDM0ZjcyYy05MjA0LTRmNmMtOGZhZC00MTkyNmQzNDgwYjcifQ==",
)

neptune.create_experiment(name='great-idea',params=PARAMS)

"""This opens a new "experiment" namespace in Neptune to which you can log various objects.

Click on the link above to open this experiment in Neptune.

For now it is empty but keep the tab with experiment open to see what happens next.

## Step 4: Add logging for metrics and losses

Since we are using Keras we'll create a Callback that logs metrics and losses after every epoch.
"""

class NeptuneMonitor(keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        for metric_name, metric_value in logs.items():
            neptune.log_metric(metric_name, metric_value)

"""We need to pass it to the `callbacks` argument. """

results = model.fit(
 train_x, train_y,
 epochs= PARAMS['epoch_nr'],
 batch_size = PARAMS['batch_size'],
 validation_data = (test_x, test_y),
 callbacks=[NeptuneMonitor()]
)

#model.fit(x_train, y_train,
#         epochs=PARAMS['epoch_nr'],
#         batch_size=PARAMS['batch_size'],
#         callbacks=[NeptuneMonitor()])
import os
if os.getenv('CI') == "true":
   neptune.append_tag('ci-pipeline', os.getenv('NEPTUNE_EXPERIMENT_TAG_ID'))


neptune.stop()

